# Time Complexity

## üìå What is Time Complexity?
**Time Complexity** measures the **amount of time an algorithm takes to run** as a function of the input size `n`.

It does **not** depend on:
- Computer speed
- Programming language
- Compiler

Instead, it depends on:
- Number of operations performed
- Growth of input size

---

## ‚ùì Why Do We Need Time Complexity?
Time complexity helps us:
- Compare different algorithms
- Choose the most efficient solution
- Predict performance for large inputs
- Avoid slow programs

Example:
- Algorithm A takes 1 second for 1,000 inputs
- Algorithm B takes 1 hour for the same input  
‚û°Ô∏è We clearly choose Algorithm A

---

## üìà How Time Complexity is Measured?
Time complexity is measured by:
- Counting **basic operations** (comparisons, assignments, loops)
- Expressing them using **asymptotic notation**

---

## üßÆ Types of Time Complexity Cases

### 1Ô∏è‚É£ Best Case
Minimum time required for execution.

Example:  
Searching an element that is already at the first position.

---

### 2Ô∏è‚É£ Average Case
Average time taken for all possible inputs.

Example:  
Searching an element in the middle of an array.

---

### 3Ô∏è‚É£ Worst Case
Maximum time required for execution.

Example:  
Searching an element at the last position or not present.

> ‚ö†Ô∏è In most cases, we analyze **worst-case time complexity**.

---

## üî¢ Common Time Complexities

| Complexity | Name | Example |
|---------|------|--------|
| O(1) | Constant | Accessing array element |
| O(log n) | Logarithmic | Binary Search |
| O(n) | Linear | Linear Search |
| O(n log n) | Linearithmic | Merge Sort |
| O(n¬≤) | Quadratic | Bubble Sort |
| O(2‚Åø) | Exponential | Recursive Fibonacci |
| O(n!) | Factorial | Traveling Salesman |

---


